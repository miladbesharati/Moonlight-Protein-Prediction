{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f4342cb-d9b7-4cc8-8648-7f39cb36c8d8",
   "metadata": {},
   "source": [
    "# Protein Sequence Embedding using ESM-2 Transformer Models\n",
    "## This script extracts high-dimensional embeddings for protein sequences using ESM-2 models. It reads sequences from a CSV file, processes each sequence through a pretrained ESM-2 model to generate per-residue and per-sequence embeddings, and saves the results to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadfa56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install biopython fair-esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea16d1-c94d-4643-ae27-868c172f30b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import esm\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "\n",
    "def load_csv_file(csv_path):\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    sequences = {}\n",
    "\n",
    "    if 'protein_name' not in df.columns or 'sequence' not in df.columns:\n",
    "        raise ValueError(\"CSV file must contain 'protein_name' and 'sequence' columns\")\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        sequences[row['protein_name']] = row['sequence']\n",
    "\n",
    "    return sequences\n",
    "\n",
    "def load_esm2_model(model_name=\"esm2_t6_8M_UR50D\"):\n",
    "    model, alphabet = esm.pretrained.load_model_and_alphabet(model_name)\n",
    "    model.eval()\n",
    "    return model, alphabet\n",
    "\n",
    "def embed_protein_sequence(sequence, model, alphabet, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    data = [(\"protein1\", sequence)]\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "    batch_tokens = batch_tokens.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[6], return_contacts=False)\n",
    "\n",
    "    token_embeddings = results[\"representations\"][6]\n",
    "\n",
    "    per_residue_embedding = token_embeddings[0, 1:-1, :].cpu()\n",
    "    per_sequence_embedding = per_residue_embedding.mean(dim=0)\n",
    "\n",
    "    return per_residue_embedding, per_sequence_embedding\n",
    "\n",
    "def get_esm_embeddings_from_csv(csv_path, model_name=\"esm2_t6_8M_UR50D\", batch_size=1):\n",
    "\n",
    "    sequences = load_csv_file(csv_path)\n",
    "\n",
    "    model, alphabet = load_esm2_model(model_name)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    results = {\n",
    "        'sequence_ids': [],\n",
    "        'sequences': [],\n",
    "        'per_residue_embeddings': [],\n",
    "        'per_sequence_embeddings': [],\n",
    "        'embedding_dimension': None\n",
    "    }\n",
    "\n",
    "    for i, (seq_id, sequence) in enumerate(sequences.items()):\n",
    "        print(f\"Processing sequence {i+1}/{len(sequences)}: {seq_id}\")\n",
    "\n",
    "        try:\n",
    "            # Get embeddings\n",
    "            residue_embeds, seq_embed = embed_protein_sequence(sequence, model, alphabet, device)\n",
    "\n",
    "            # Store results\n",
    "            results['sequence_ids'].append(seq_id)\n",
    "            results['sequences'].append(sequence)\n",
    "            results['per_residue_embeddings'].append(residue_embeds.numpy())\n",
    "            results['per_sequence_embeddings'].append(seq_embed.numpy())\n",
    "\n",
    "            if results['embedding_dimension'] is None:\n",
    "                results['embedding_dimension'] = seq_embed.shape[0]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sequence {seq_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return results\n",
    "\n",
    "def save_embeddings_to_csv(results, output_dir=\"embeddings\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Create DataFrame for per-sequence embeddings\n",
    "    seq_embeddings = np.array(results['per_sequence_embeddings'])\n",
    "    embedding_dim = results['embedding_dimension']\n",
    "\n",
    "    # Create column names for the embedding dimensions\n",
    "    feature_columns = [f'feature_{i}' for i in range(embedding_dim)]\n",
    "\n",
    "    # Create DataFrame with sequence IDs and embeddings\n",
    "    df_embeddings = pd.DataFrame(seq_embeddings, columns=feature_columns)\n",
    "    df_embeddings.insert(0, 'sequence_id', results['sequence_ids'])\n",
    "    df_embeddings.insert(1, 'sequence', results['sequences'])\n",
    "\n",
    "    # Save to CSV\n",
    "    # csv_path = os.path.join(output_dir, 'per_sequence_embeddings.csv')\n",
    "    df_embeddings.to_csv(csv_path, index=False)\n",
    "\n",
    "    # Also save a metadata file\n",
    "    metadata_df = pd.DataFrame({\n",
    "        'sequence_id': results['sequence_ids'],\n",
    "        'sequence_length': [len(seq) for seq in results['sequences']],\n",
    "        'embedding_dimension': embedding_dim\n",
    "    })\n",
    "    metadata_df.to_csv(os.path.join(output_dir, 'metadata.csv'), index=False)\n",
    "\n",
    "    print(f\"Saved {len(seq_embeddings)} embeddings to CSV files in {output_dir}/\")\n",
    "    print(f\"Embedding dimension: {embedding_dim}\")\n",
    "    print(f\"Shape of per-sequence embeddings: {seq_embeddings.shape}\")\n",
    "    print(f\"CSV file saved: {csv_path}\")\n",
    "\n",
    "    return df_embeddings\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    csv_file_path = \".../Plant/Non_MP_final_clean.csv\"\n",
    "    csv_path = \".../Plant/ESM/ESM_Non_MP_Final.csv\"\n",
    "    embeddings = get_esm_embeddings_from_csv(csv_file_path)\n",
    "\n",
    "    df_embeddings = save_embeddings_to_csv(embeddings)\n",
    "\n",
    "    print(f\"\\nFirst few rows of the CSV:\")\n",
    "    print(df_embeddings.head())\n",
    "    print(f\"\\nTotal sequences processed: {len(embeddings['sequence_ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1a82a-9345-41f6-8493-886a1457b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings.to_csv(r'.../ESM_DnaBinding_Neg1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
