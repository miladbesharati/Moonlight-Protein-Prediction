{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f4342cb-d9b7-4cc8-8648-7f39cb36c8d8",
   "metadata": {},
   "source": [
    "# Baseline Classifiers for Tf-Idf\n",
    "## 10-Fold Cross-Validation of Protein Sequence Classifiers Using 2-mer TF–IDF Features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c976c77-e8d1-4867-93a4-f16715bc8226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab import drive\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import  History\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.activations import swish\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadfa56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "classifiers = [\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(random_state=42)),\n",
    "    (\"SVM\", SVC(kernel='rbf', C=10, gamma='auto', probability=True, random_state=42)),\n",
    "    (\"Random Forest\", RandomForestClassifier(n_estimators=500, random_state=42)),\n",
    "    (\"MLP\", MLPClassifier(hidden_layer_sizes=(200, 45),\n",
    "                         activation='relu',\n",
    "                         solver='adam',\n",
    "                         batch_size=128,\n",
    "                         max_iter=200,\n",
    "                         random_state=42)),\n",
    "    (\"Naive Bayes\", GaussianNB()),\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=1000, random_state=42)),\n",
    "    (\"K-Nearest Neighbors\", KNeighborsClassifier(n_neighbors=5)),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "def compute_tfidf_for_fold(train_sequences, test_sequences, kmer_length=2, predefined_aa=list('ACDEFGHIKLMNPQRSTUVWY')):\n",
    "    feature_names = [''.join(km) for km in product(predefined_aa, repeat=kmer_length)]\n",
    "    M = len(feature_names)\n",
    "    kmer_to_idx = {kmer: idx for idx, kmer in enumerate(feature_names)}\n",
    "\n",
    "    N_train = len(train_sequences)\n",
    "    df_vector = np.zeros(M)\n",
    "\n",
    "    for seq in train_sequences:\n",
    "        kmers_in_seq = [seq[i:i + kmer_length] for i in range(len(seq) - kmer_length + 1)]\n",
    "        unique_kmers_in_seq = set(kmers_in_seq) & set(feature_names)\n",
    "        for kmer in unique_kmers_in_seq:\n",
    "            df_vector[kmer_to_idx[kmer]] += 1\n",
    "\n",
    "    idf_vector = np.log((N_train + 1) / (df_vector + 1))\n",
    "\n",
    "    tfidf_train = np.zeros((len(train_sequences), M))\n",
    "    for seq_idx, seq in enumerate(train_sequences):\n",
    "        kmers = [seq[i:i + kmer_length] for i in range(len(seq) - kmer_length + 1)]\n",
    "        tf_counts = Counter([k for k in kmers if k in kmer_to_idx])\n",
    "        tf_vector = np.array([tf_counts.get(feature_names[j], 0) for j in range(M)])\n",
    "        raw_tfidf = tf_vector * idf_vector\n",
    "        norm = np.linalg.norm(raw_tfidf, ord=2)\n",
    "        if norm > 0:\n",
    "            tfidf_train[seq_idx] = raw_tfidf / norm\n",
    "        else:\n",
    "            tfidf_train[seq_idx] = raw_tfidf\n",
    "\n",
    "    tfidf_test = np.zeros((len(test_sequences), M))\n",
    "    for seq_idx, seq in enumerate(test_sequences):\n",
    "        kmers = [seq[i:i + kmer_length] for i in range(len(seq) - kmer_length + 1)]\n",
    "        tf_counts = Counter([k for k in kmers if k in kmer_to_idx])\n",
    "        tf_vector = np.array([tf_counts.get(feature_names[j], 0) for j in range(M)])\n",
    "        raw_tfidf = tf_vector * idf_vector\n",
    "        norm = np.linalg.norm(raw_tfidf, ord=2)\n",
    "        if norm > 0:\n",
    "            tfidf_test[seq_idx] = raw_tfidf / norm\n",
    "        else:\n",
    "            tfidf_test[seq_idx] = raw_tfidf\n",
    "\n",
    "    # CORRECTED: Return tfidf_test instead of tf_test\n",
    "    return tfidf_train, tfidf_test, feature_names\n",
    "\n",
    "my_amino_acids = list('ACDEFGHIKLMNPQRSTUVWY')\n",
    "\n",
    "sequenceMP_ids, sequencesMP = read_sequences_from_csv(\"/content/drive/MyDrive/MP_Prediction_MB/MPFit/MP_clean.csv\")\n",
    "sequenceNonMP_ids, sequencesNonMP = read_sequences_from_csv(\"/content/drive/MyDrive/MP_Prediction_MB/MPFit/Non_MP_clean.csv\")\n",
    "\n",
    "all_sequences = sequencesMP + sequencesNonMP\n",
    "all_labels = [1] * len(sequencesMP) + [0] * len(sequencesNonMP)\n",
    "\n",
    "all_sequences = np.array(all_sequences)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(all_sequences)):\n",
    "    print(f\"\\n=== Fold {fold + 1}/10 ===\")\n",
    "\n",
    "    X_train_fold, X_test_fold = all_sequences[train_idx], all_sequences[test_idx]\n",
    "    y_train_fold, y_test_fold = all_labels[train_idx], all_labels[test_idx]\n",
    "\n",
    "    print(f\"Training samples: {len(X_train_fold)}, Test samples: {len(X_test_fold)}\")\n",
    "\n",
    "    X_train_tfidf, X_test_tfidf, feature_names = compute_tfidf_for_fold(\n",
    "        X_train_fold, X_test_fold, kmer_length=2, predefined_aa=my_amino_acids\n",
    "    )\n",
    "\n",
    "    print(f\"TF-IDF features computed. Training shape: {X_train_tfidf.shape}, Test shape: {X_test_tfidf.shape}\")\n",
    "\n",
    "    for clf_name, clf in classifiers:\n",
    "        # Train the classifier\n",
    "        clf.fit(X_train_tfidf, y_train_fold)\n",
    "\n",
    "        # Get predictions and probabilities\n",
    "        y_pred = clf.predict(X_test_tfidf)\n",
    "        y_pred_proba = clf.predict_proba(X_test_tfidf)[:, 1]  # Probability of positive class\n",
    "\n",
    "        # Calculate all metrics\n",
    "        accuracy = accuracy_score(y_test_fold, y_pred)\n",
    "        precision = precision_score(y_test_fold, y_pred, average='binary')\n",
    "        recall = recall_score(y_test_fold, y_pred, average='binary')\n",
    "        f1 = f1_score(y_test_fold, y_pred, average='binary')\n",
    "        auc = roc_auc_score(y_test_fold, y_pred_proba)\n",
    "\n",
    "        # Calculate AUPR (Average Precision)\n",
    "        aupr = average_precision_score(y_test_fold, y_pred_proba)\n",
    "\n",
    "        results.append({\n",
    "            'fold': fold + 1,\n",
    "            'classifier': clf_name,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'auc': auc,\n",
    "            'aupr': aupr\n",
    "        })\n",
    "\n",
    "        print(f\"{clf_name}: Acc = {accuracy:.4f}, Prec = {precision:.4f}, Rec = {recall:.4f}, F1 = {f1:.4f}, AUC = {auc:.4f}, AUPR = {aupr:.4f}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "mean_results = results_df.groupby('classifier').agg({\n",
    "    'accuracy': ['mean', 'std'],\n",
    "    'precision': ['mean', 'std'],\n",
    "    'recall': ['mean', 'std'],\n",
    "    'f1_score': ['mean', 'std'],\n",
    "    'auc': ['mean', 'std'],\n",
    "    'aupr': ['mean', 'std']\n",
    "}).round(4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-VALIDATION RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(mean_results)\n",
    "\n",
    "print(\"\\nDetailed results by fold:\")\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv('cross_validation_results_with_auc_aupr.csv', index=False)\n",
    "\n",
    "summary_table = pd.DataFrame({\n",
    "    'Classifier': mean_results.index,\n",
    "    'Accuracy (mean±std)': [f\"{mean_results['accuracy']['mean'][i]:.4f}±{mean_results['accuracy']['std'][i]:.4f}\" for i in range(len(mean_results))],\n",
    "    'Precision (mean±std)': [f\"{mean_results['precision']['mean'][i]:.4f}±{mean_results['precision']['std'][i]:.4f}\" for i in range(len(mean_results))],\n",
    "    'Recall (mean±std)': [f\"{mean_results['recall']['mean'][i]:.4f}±{mean_results['recall']['std'][i]:.4f}\" for i in range(len(mean_results))],\n",
    "    'F1-Score (mean±std)': [f\"{mean_results['f1_score']['mean'][i]:.4f}±{mean_results['f1_score']['std'][i]:.4f}\" for i in range(len(mean_results))],\n",
    "    'AUC (mean±std)': [f\"{mean_results['auc']['mean'][i]:.4f}±{mean_results['auc']['std'][i]:.4f}\" for i in range(len(mean_results))],\n",
    "    'AUPR (mean±std)': [f\"{mean_results['aupr']['mean'][i]:.4f}±{mean_results['aupr']['std'][i]:.4f}\" for i in range(len(mean_results))]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FORMATTED SUMMARY TABLE\")\n",
    "print(\"=\"*100)\n",
    "print(summary_table.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
